{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pandas，并且重命名为pd。\n",
    "import pandas as pd\n",
    "\n",
    "# 通过互联网读取泰坦尼克乘客档案，并存储在变量titanic中。\n",
    "titanic = pd.read_csv('titanic.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人工选取pclass、age以及sex作为判别乘客是否能够生还的特征。\n",
    "X = titanic[['pclass', 'age', 'sex']]\n",
    "y = titanic['survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# 对于缺失的年龄信息，我们使用全体乘客的平均年龄代替，这样可以在保证顺利训练模型的同时，尽可能不影响预测任务。\n",
    "X['age'].fillna(X['age'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对原始数据进行分割，25%的乘客数据用于测试。\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对类别型特征进行转化，成为特征向量。\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec = DictVectorizer(sparse=False)\n",
    "X_train = vec.fit_transform(X_train.to_dict(orient='record'))\n",
    "X_test = vec.transform(X_test.to_dict(orient='record'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用单一决策树进行模型训练以及预测分析。\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "dtc_y_pred = dtc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用随机森林分类器进行集成模型的训练以及预测分析。\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_y_pred = rfc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用梯度提升决策树进行集成模型的训练以及预测分析。\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train, y_train)\n",
    "gbc_y_pred = gbc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of decision tree is 0.7811550151975684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       236\n",
      "           1       0.58      0.80      0.67        93\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.74      0.79      0.75       329\n",
      "weighted avg       0.81      0.78      0.79       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从sklearn.metrics导入classification_report。\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 输出单一决策树在测试集上的分类准确性，以及更加详细的精确率、召回率、F1指标。\n",
    "print('The accuracy of decision tree is', dtc.score(X_test, y_test))\n",
    "print(classification_report(dtc_y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of random forest classifier is 0.7811550151975684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83       234\n",
      "           1       0.59      0.79      0.68        95\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.75      0.78      0.76       329\n",
      "weighted avg       0.81      0.78      0.79       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 输出随机森林分类器在测试集上的分类准确性，以及更加详细的精确率、召回率、F1指标。\n",
    "print('The accuracy of random forest classifier is', rfc.score(X_test, y_test))\n",
    "print(classification_report(rfc_y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of gradient tree boosting is 0.790273556231003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.84       239\n",
      "           1       0.58      0.82      0.68        90\n",
      "\n",
      "    accuracy                           0.79       329\n",
      "   macro avg       0.75      0.80      0.76       329\n",
      "weighted avg       0.83      0.79      0.80       329\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 输出梯度提升决策树在测试集上的分类准确性，以及更加详细的精确率、召回率、F1指标。\n",
    "print('The accuracy of gradient tree boosting is', gbc.score(X_test, y_test))\n",
    "print(classification_report(gbc_y_pred, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
